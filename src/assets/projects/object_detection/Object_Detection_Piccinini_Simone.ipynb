{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27b895cd",
   "metadata": {},
   "source": [
    "# YOLOv5 Object Detection, Simone Piccinini \n",
    "\n",
    "This notebook demonstrates how to set up and use YOLOv5 for object detection tasks. \n",
    "\n",
    "## What is YOLOv5?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569cb64c",
   "metadata": {},
   "source": [
    "YOLO is an acronym for **“You Only Look Once”** and it has that name because this is a real-time object detection algorithm that processes images very fast.\n",
    "It is a single-stage object detector that uses a convolutional neural network (CNN) to predict the bounding boxes and class probabilities of objects in input images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a203bb5",
   "metadata": {},
   "source": [
    "## How Does it works? **_reference_** [Yolo how does it works](https://kili-technology.com/data-labeling/machine-learning/yolo-algorithm-real-time-object-detection-from-a-to-z).\n",
    "\n",
    "### The basic idea behind YOLO is to divide the input image into a grid of cells and, for each cell, predict the probability of the presence of an object and the bounding box coordinates of the object. The process of YOLO can be broken down into several steps:\n",
    "\n",
    "1. Input image is passed through a CNN to extract features from the image.\n",
    "\n",
    "2. The features are then passed through a series of fully connected layers, which predict ‌class probabilities and bounding box coordinates.\n",
    "\n",
    "3. The image is divided into a grid of cells, and each cell is responsible for predicting a set of bounding boxes and class probabilities.\n",
    "\n",
    "4. The output of the network is a set of bounding boxes and class probabilities for each cell.\n",
    "\n",
    "5. The bounding boxes are then filtered using a post-processing algorithm called non-max suppression to remove overlapping boxes and choose the box with the highest probability.\n",
    "\n",
    "6. The final output is a set of predicted bounding boxes and class labels for each object in the image.\n",
    "\n",
    "One of the key advantages of YOLO is that it processes the entire image in one pass, making it faster and more efficient than two-stage object detectors such as R-CNN and its variants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f76f23f",
   "metadata": {},
   "source": [
    "![](https://a.storyblok.com/f/139616/1200x800/297c23f45f/structure-of-yolo.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1e99e1",
   "metadata": {},
   "source": [
    "## CPU-Based Processing Explanation\n",
    "\n",
    "In this project, CUDA is not utilized because the current system is equipped with an AMD GPU, specifically I have the RADEON RX 470, which does not support CUDA because it's specifically designed for NVIDIA GPUs.\n",
    "\n",
    "CUDA, is a parallel computing platform developed by NVIDIA that is exclusive to NVIDIA GPUs. As a result, the deep learning framework, PyTorch, will default to using the CPU for all computations. While this may result in slower processing times compared to utilizing a CUDA-compatible GPU.\n",
    "Regardless of the use of the CPU the functionality and accuracy of the object detection tasks performed by YOLOv5 remain unaffected.\n",
    "\n",
    "The results you are going to see are based using the CPU: Intel(R) Core(TM) i5-9400F CPU, 2.90 GHz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c688a3a9",
   "metadata": {},
   "source": [
    "## 1. Install and Import Dependencies\n",
    "\n",
    "First, we need to install the required libraries: `torch`, `torchvision`, `torchaudio`, and clone the YOLOv5 repository. \n",
    "We also need to install the dependencies specified in the YOLOv5 repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcd258f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio\n",
    "!git clone https://github.com/ultralytics/yolov5\n",
    "!cd yolov5 && pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69203b5",
   "metadata": {},
   "source": [
    "## 2. Import Necessary Libraries\n",
    "\n",
    "We will import the required libraries for our task. These include `torch` for loading the YOLOv5 model, `matplotlib` for displaying images, `numpy` for numerical operations, and `cv2` from OpenCV for handling image and video data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eac0d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa279bca",
   "metadata": {},
   "source": [
    "# 3. Load YOLOv5 Model\n",
    "\n",
    "We load the pre-trained YOLOv5 model using the PyTorch Hub API. The model will be downloaded and cached for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d65a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66df2c62",
   "metadata": {},
   "source": [
    "The output indicates that the YOLOv5s model has been successfully loaded. The model summary shows its architecture, number of layers, parameters, and other details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fca4507",
   "metadata": {},
   "source": [
    "# 4. Classes\n",
    "\n",
    "You can list all the class names that the YOLOv5 model can recognize running this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5661e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
    "\n",
    "class_names = model.names\n",
    "print(class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf342bb",
   "metadata": {},
   "source": [
    "# 5. Perform Object Detection on an Image\n",
    "\n",
    "We will use the loaded YOLOv5 model to perform object detection on a sample image from a URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbca7b82",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# URL of the image\n",
    "img_url = 'https://ilfattoalimentare.it/wp-content/uploads/2015/06/supermercato-spesa-06photo-fotolia-750.jpg'\n",
    "\n",
    "# Perform inference\n",
    "results = model(img_url)\n",
    "\n",
    "# Print results\n",
    "results.print()\n",
    "\n",
    "# Display image with results\n",
    "%matplotlib inline\n",
    "plt.imshow(np.squeeze(results.render()))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1924818c",
   "metadata": {},
   "source": [
    "The above code fetches an image from the provided URL, performs inference using the YOLOv5 model, prints the detection results, and displays the image with detected objects.\n",
    "\n",
    "## Result\n",
    "\n",
    "If the image has been correctly processed, you will see each detected object enclosed in a rectangle (**Bounding Box**). On top of this box, there is a **Class Label** that represents the name of the class, along with a **Confidence Score** that indicates the percentage confidence level of the model in its prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f70a9cc",
   "metadata": {},
   "source": [
    "# 6. Real-Time Object Detection Using Webcam\n",
    "\n",
    "Finally, we perform real-time object detection using a webcam. We capture frames from the webcam, run inference on each frame, and display the results in real-time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796995d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load YOLOv5 model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(1) # change this number if the script can't find your webcam\n",
    "\n",
    "# Check if webcam is opened correctly\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to capture image\")\n",
    "        break\n",
    "\n",
    "    print(f\"Captured frame shape: {frame.shape}, dtype: {frame.dtype}\")\n",
    "\n",
    "    try:\n",
    "        # Perform inference on the frame\n",
    "        results = model(frame)\n",
    "\n",
    "        # Render the results on the frame\n",
    "        rendered_frame = np.squeeze(results.render())\n",
    "        \n",
    "        print(f\"Rendered frame shape: {rendered_frame.shape}, dtype: {rendered_frame.dtype}\")\n",
    "\n",
    "        # Ensure the rendered frame is valid\n",
    "        if rendered_frame is None or rendered_frame.size == 0:\n",
    "            print(\"Failed to render frame\")\n",
    "            break\n",
    "\n",
    "        # Display the rendered frame\n",
    "        cv2.imshow('YOLO', rendered_frame)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during inference: {e}\")\n",
    "        break\n",
    "\n",
    "    # Break the loop when 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture and destroy all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a788f5",
   "metadata": {},
   "source": [
    "This code initializes the webcam, captures frames in a loop, performs inference on each frame using the YOLOv5 model, and displays the results. The loop can be stopped by pressing the 'q' key."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edec835",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "This notebook, demostrates how to set up and use YOLOv5 for object detection tasks. We installed the necessary dependencies, loaded a pre-trained YOLOv5 model, performed object detection on a sample image, and ran real-time object detection using a webcam.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
